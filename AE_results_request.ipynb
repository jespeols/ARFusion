{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results request - CAZ_R performance on TESSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import wandb\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "BASE_DIR = Path(os.path.abspath(''))\n",
    "sys.path.append(str(BASE_DIR))\n",
    "os.chdir(BASE_DIR)\n",
    "\n",
    "# user-defined modules\n",
    "from multimodal.models import BERT\n",
    "from multimodal.datasets import MMFinetuneDataset\n",
    "from multimodal.trainers import MMBertFineTuner\n",
    "\n",
    "# user-defined functions\n",
    "from utils import get_split_indices, export_results, get_average_and_std_df\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(\"config_MM.yaml\"))\n",
    "data_config = config['data']\n",
    "defined_antibiotics = sorted(list(set(data_config['antibiotics']['abbr_to_names'].keys()) - set(data_config['exclude_antibiotics'])))\n",
    "ab_to_idx = {ab: idx for idx, ab in enumerate(defined_antibiotics)}\n",
    "specials = config['specials']\n",
    "cls_token, pad_token, mask_token = specials['CLS'], specials['PAD'], specials['MASK']\n",
    "max_seq_len = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMK': 0,\n",
       " 'AMP': 1,\n",
       " 'CAZ': 2,\n",
       " 'CIP': 3,\n",
       " 'CRO': 4,\n",
       " 'CTX': 5,\n",
       " 'ETP': 6,\n",
       " 'FEP': 7,\n",
       " 'GEN': 8,\n",
       " 'IPM': 9,\n",
       " 'LVX': 10,\n",
       " 'MEM': 11,\n",
       " 'MFX': 12,\n",
       " 'NAL': 13,\n",
       " 'TOB': 14}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare dataset for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in TESSy: 3,303,501\n"
     ]
    }
   ],
   "source": [
    "# ds_path = data_config['TESSy']['load_path']\n",
    "ds_path = 'data/TESSy_15_all_pathogens.pkl'\n",
    "ds_TESSy = pd.read_pickle(ds_path)\n",
    "ds_NCBI = pd.read_pickle(data_config['NCBI']['load_path'])\n",
    "ds_MM = ds_NCBI[ds_NCBI['num_ab'] > 1].reset_index(drop=True)\n",
    "print(f\"Total number of samples in TESSy: {len(ds_TESSy):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAZ_R experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected samples in ds_CAZ: 709,573\n"
     ]
    }
   ],
   "source": [
    "antibiotics = ['CAZ', 'CIP', 'AMP', 'GEN'] # original request\n",
    "ds_CAZ = ds_TESSy.copy()\n",
    "ds_CAZ['phenotypes'] = ds_CAZ['phenotypes'].apply(lambda x: [p for p in x if p.split('_')[0] in antibiotics])\n",
    "# ds_CAZ = ds_CAZ[ds_CAZ['phenotypes'].apply(lambda x: 'CAZ_R' in x)].reset_index(drop=True)\n",
    "ds_CAZ = ds_CAZ[ds_CAZ['phenotypes'].apply(lambda x: all([ab in [p.split('_')[0] for p in x] for ab in antibiotics]))].reset_index(drop=True)\n",
    "ds_CAZ['country'] = ds_CAZ['country'].map(config['data']['TESSy']['country_code_to_name'])\n",
    "ds_CAZ.drop(columns=['num_R', 'num_S', 'num_ab'], inplace=True)\n",
    "ds_CAZ = ds_CAZ.sample(frac=1, random_state=config['random_state']).reset_index(drop=True)\n",
    "print(f\"Number of selected samples in ds_CAZ: {len(ds_CAZ):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIP_R experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected samples in ds_CIP: 34,404\n"
     ]
    }
   ],
   "source": [
    "antibiotics = ['CIP', 'AMP', 'CAZ', 'CTX', 'CRO', 'ETP', 'FEP']\n",
    "ds_CIP = ds_TESSy.copy()\n",
    "ds_CIP['phenotypes'] = ds_CIP['phenotypes'].apply(lambda x: [p for p in x if p.split('_')[0] in antibiotics])\n",
    "# ds_CIP = ds_CIP[ds_CIP['phenotypes'].apply(lambda x: 'CIP_R' in x)].reset_index(drop=True)\n",
    "ds_CIP = ds_CIP[ds_CIP['phenotypes'].apply(lambda x: all([ab in [p.split('_')[0] for p in x] for ab in antibiotics]))].reset_index(drop=True)\n",
    "ds_CIP['country'] = ds_CIP['country'].map(config['data']['TESSy']['country_code_to_name'])\n",
    "ds_CIP.drop(columns=['num_R', 'num_S', 'num_ab'], inplace=True)\n",
    "ds_CIP = ds_CIP.sample(frac=1, random_state=config['random_state']).reset_index(drop=True)\n",
    "print(f\"Number of selected samples in ds_CIP: {len(ds_CIP):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected ab: CIP\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# vocab_path = BASE_DIR / config['fine_tuning']['loadpath_vocab']\n",
    "vocab_path = BASE_DIR / 'MM_vocab_15_2mask.pt'\n",
    "vocab = torch.load(vocab_path)\n",
    "\n",
    "class MMInferenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds, vocab, defined_antibiotics, max_seq_len, specials, selected_ab_idx):\n",
    "        self.ds = ds\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.specials = specials\n",
    "        self.CLS, self.PAD, self.MASK = specials['CLS'], specials['PAD'], specials['MASK']\n",
    "        self.device = device\n",
    "        self.ab = defined_antibiotics[selected_ab_idx]\n",
    "        \n",
    "        self.phenotypes = self.ds['phenotypes'].tolist()\n",
    "        self.year_col = self.ds['year'].astype(str).tolist()\n",
    "        self.country_col = self.ds['country'].tolist()\n",
    "        self.gender_col = self.ds['gender'].tolist()\n",
    "        self.age_col = self.ds['age'].astype(int).astype(str).tolist()\n",
    "        \n",
    "        self.columns = ['indices_masked', 'token_types', 'attn_mask', 'target_res', 'masked_sequences']\n",
    "        \n",
    "    def prepare_dataset(self):\n",
    "        masked_phenotypes = []\n",
    "        target_res = []\n",
    "        for phen_list in self.phenotypes:\n",
    "            masked_phen_list = []\n",
    "            for p in phen_list:\n",
    "                if p.split('_')[0] != self.ab:\n",
    "                    masked_phen_list.append(p)\n",
    "                    # pass\n",
    "                else:\n",
    "                    if p == self.ab+'_R':\n",
    "                        target_res.append(1)\n",
    "                    else:\n",
    "                        target_res.append(0)\n",
    "                    # masked_phen_list.append(specials['MASK'])\n",
    "                    masked_phen_list.append(specials['AB_MASK'])\n",
    "            masked_phenotypes.append(masked_phen_list)\n",
    "\n",
    "        masked_sequences = [[specials['CLS'], self.year_col[i], self.country_col[i], self.gender_col[i], self.age_col[i]] + masked_phenotypes[i] for i in range(len(self.ds))]\n",
    "        token_types = [[0]*5 + [2]*(len(masked_sequences[i])-5) for i in range(len(self.ds))]\n",
    "        ########### without patient info ###########\n",
    "        # masked_sequences = [[specials['CLS']] + masked_phenotypes[i] for i in range(len(self.ds))]\n",
    "        # token_types = [[0] + [2]*(len(masked_sequences[i])-1) for i in range(len(self.ds))]\n",
    "        \n",
    "        masked_sequences = [seq + [pad_token]*(max_seq_len-len(seq)) for seq in masked_sequences]\n",
    "        indices_masked = [vocab.lookup_indices(masked_seq) for masked_seq in masked_sequences]\n",
    "        token_types = [tt + [2]*(max_seq_len-len(tt)) for tt in token_types]\n",
    "        attn_mask = [[False if token == pad_token else True for token in seq] for seq in masked_sequences]\n",
    "        \n",
    "        rows = zip(indices_masked, token_types, attn_mask, target_res, masked_sequences)\n",
    "        self.df = pd.DataFrame(rows, columns=self.columns)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "        \n",
    "        input = torch.tensor(item['indices_masked'], dtype=torch.long, device=self.device)\n",
    "        token_types = torch.tensor(item['token_types'], dtype=torch.long, device=self.device)\n",
    "        masked_sequences = item['masked_sequences']\n",
    "        target_res = torch.tensor(item['target_res'], dtype=torch.float, device=self.device)\n",
    "        attn_mask = (input != self.vocab[self.PAD]).unsqueeze(0).unsqueeze(1)\n",
    "        \n",
    "        return input, token_types, attn_mask, target_res\n",
    "\n",
    "CAZ_idx = ab_to_idx['CAZ']\n",
    "CIP_idx = ab_to_idx['CIP']\n",
    "AMP_idx = ab_to_idx['AMP']\n",
    "GEN_idx = ab_to_idx['GEN']\n",
    "CTX_idx = ab_to_idx['CTX']\n",
    "\n",
    "ds = ds_CAZ.copy()\n",
    "num_samples = 40000\n",
    "ab_idx = CAZ_idx\n",
    "\n",
    "ds = ds_CIP.copy()\n",
    "num_samples = len(ds_CIP)\n",
    "ab_idx = CIP_idx\n",
    "\n",
    "selected_ab = defined_antibiotics[ab_idx]\n",
    "print(\"selected ab:\", selected_ab)\n",
    "\n",
    "ds_inference = MMInferenceDataset(ds.iloc[:num_samples], vocab, defined_antibiotics, max_seq_len, specials, ab_idx)\n",
    "inference_loader = DataLoader(ds_inference, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load vocab & fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 1571\n",
      "selected ab CIP\n"
     ]
    }
   ],
   "source": [
    "###################################### pre-trained models ###############################\n",
    "# model_name = '0.5_2known_WL'\n",
    "# model_path = 'results/MM/AE_request/PT_with_eval_xknown/'+model_name+'/model_state.pt'\n",
    "\n",
    "# model_name = 'easyCPT'                            # dumb/0.27 for CAZ, /0.4 for CIP\n",
    "# model_path = 'results/MM/PT_2024_04_09/'+model_name+'/model_state.pt'\n",
    "\n",
    "# model_path = 'results/MM/PT_0.75_3known_strong_WL/model_state.pt' # dumb/0.69 for CAZ, 0.22/0.66 for CIP\n",
    "############################## pre-trained + fine-tuned models #################################\n",
    "# model_name = 'FT_3known_WL'                     # 0.21/0.57 for CAZ, dumb/0.42 for CIP (PT was 0.5_2known_WL)\n",
    "# model_name = 'FT_3known_strong_WL'              # 0.43/0.68 for CAZ, 0.25/0.50 for CIP (PT was 0.5_2known_WL) - BEST?\n",
    "# model_name = 'FT_0.2_strong_WL'                 # 0.66/0.77 for CAZ, 0.89/0.75 for CIP (PT was 0.5_2known_WL)\n",
    "# model_name = 'FT_class_WL'                      # 0.04/0.53 for CAZ, 0.74/0.61 for CIP (PT was 0.5_2known_WL)\n",
    "# model_name = 'FT_class_strong_WL'               # dumb/0.76 for CAZ, (0.90)/(0.82) for CIP (PT was 0.5_2known_WL)\n",
    "# model_name = 'FT_0known_WL'                     # 0.8/0.76 for CAZ, (0.86)/0.56 for CIP (PT was 0.5_2known_WL)\n",
    "\n",
    "# model_name = 'FT_easyCPT_3known'                # 0.67/0.87 for CAZ, dumb/0.38 for CIP (PT was easyCPT)\n",
    "# model_name = 'FT_easyCPT_3known_WL'             # 0.85/0.90 for CAZ, 0.09/0.42 for CIP (PT was easyCPT)\n",
    "# model_name = 'FT_easyCPT_3known_strong_WL'      # (0.89)/0.63 for CAZ, 0.53/0.45 for CIP (PT was easyCPT)\n",
    "\n",
    "# model_name = 'FT_3knownPT_3known'               # dumb/0.44 for CAZ, dumb/0.18 for CIP (PT was 0.75_3known_strong_WL)\n",
    "# model_name = 'FT_3knownPT_3known_WL'            # (0.02)/0.45 for CAZ, 0.0/0.54 for CIP (PT was 0.75_3known_strong_WL)\n",
    "# model_name = 'FT_3knownPT_3known_strong_WL'     # 0.0/0. for CAZ, 0./0. for CIP (PT was 0.75_3known_strong_WL)\n",
    "# model_name = 'FT_3knownPT_class_WL'             # 0.03/0.37 for CAZ, (0.91)/0.66 for CIP (PT was 0.75_3known_strong_WL)\n",
    "\n",
    "# model_name = 'FT_2mask_3known_WL'                # 0.02/0.25 for CAZ, 0.0/0.35 for CIP (PT was 2_mask/0.75_3known_WL)\n",
    "# model_name = 'FT_2mask_3known_lr1e-5_WL'         # 0.01/0.38 for CAZ, 0.0/0.40 for CIP (PT was 2_mask/0.75_3known_WL)\n",
    "# model_name = 'FT_2mask_3known_strong_WL'         # 0.05/0.29 for CAZ, 0.03/0.40 for CIP (PT was 2_mask/0.75_3known_WL)\n",
    "model_path = 'results/MM/AE_request/'+model_name+'/model_state.pt'\n",
    "############################# pre-trained and fine-tuned on TESSy ##################################\n",
    "# model_name = ''\n",
    "# model_path = 'results/MM/'+model_name+'/model_state.pt'\n",
    "########################### pre-trained models with 2-mask strategy ##################################\n",
    "# model_name ='PT_0.75_0.2_WL'\n",
    "# model_name ='PT_0.75_0.8_WL'\n",
    "# model_path = 'results/MM/2_mask/'+model_name+'/model_state.pt'\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"vocab size\", vocab_size)\n",
    "num_ab = 15 # from fine-tuning\n",
    "\n",
    "bert = BERT(\n",
    "    config,\n",
    "    vocab_size=vocab_size,\n",
    "    max_seq_len=max_seq_len,\n",
    "    num_ab=num_ab,\n",
    "    pad_idx=vocab[pad_token],\n",
    "    pheno_only=True\n",
    ").to(device)\n",
    "print(\"selected ab\", selected_ab)\n",
    "# print(\"Randomly initialized model:\")\n",
    "# print(bert.classification_layer[ab_idx].state_dict()['classifier.3.weight'])\n",
    "# print(bert.classification_layer[ab_idx].state_dict()['classifier.3.bias'])\n",
    "# print(\"Saved model:\")\n",
    "# print(torch.load(model_path)['ab_predictors'][ab_idx]['classifier.3.weight'])\n",
    "# print(torch.load(model_path)['ab_predictors'][ab_idx]['classifier.3.bias'])\n",
    "bert.set_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_pickle('results/MM/PT_with_eval_xknown/0.5_2known_WL/pt_results.pkl')\n",
    "# results = pd.read_pickle('results/MM/2_mask/'+model_name+'/pt_results.pkl')\n",
    "# print(results.keys())\n",
    "# results['val_ab_stats'].set_index('antibiotic').loc[selected_ab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FT_2mask_3known_lr1e-5_WL\n",
      "selected ab: CIP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_masked_tot    742.000000\n",
       "num_masked_S      595.000000\n",
       "num_masked_R      147.000000\n",
       "num_pred_S        557.000000\n",
       "num_pred_R        185.000000\n",
       "num_correct       684.000000\n",
       "num_correct_S     547.000000\n",
       "num_correct_R     137.000000\n",
       "accuracy            0.921833\n",
       "sensitivity         0.931973\n",
       "specificity         0.919328\n",
       "precision           0.740541\n",
       "F1                  0.825301\n",
       "Name: CIP, dtype: float64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model:\", model_name)\n",
    "results = pd.read_pickle('results/MM/AE_request/'+model_name+'/CV_results.pkl')\n",
    "print(\"selected ab:\", selected_ab)\n",
    "results['ab_stats'][0].set_index('antibiotic').loc[selected_ab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_NCBI_CAZ = ds_MM.copy()\n",
    "# ds_NCBI_CAZ.fillna(pad_token, inplace=True)\n",
    "# ds_NCBI_CAZ['phenotypes'] = ds_NCBI_CAZ['phenotypes'].apply(lambda x: [p for p in x if p.split('_')[0] in antibiotics])\n",
    "# # ds_NCBI_CAZ = ds_NCBI_CAZ[ds_NCBI_CAZ['phenotypes'].apply(lambda x: 'CAZ_R' in x)].reset_index(drop=True)\n",
    "# ds_NCBI_CAZ = ds_NCBI_CAZ[ds_NCBI_CAZ['phenotypes'].apply(lambda x: all([ab in [p.split('_')[0] for p in x] for ab in antibiotics]))].reset_index(drop=True)\n",
    "# ds_NCBI_CAZ.head()\n",
    "# print(f\"Number of selected samples: {len(ds_NCBI_CAZ):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = torch.load(BASE_DIR / config['fine_tuning']['loadpath_vocab'])\n",
    "\n",
    "# class MMInferenceDataset_NCBI(Dataset):\n",
    "    \n",
    "#     def __init__(self, ds, vocab, defined_antibiotics, max_seq_len, specials, selected_ab_idx):\n",
    "#         self.ds = ds\n",
    "#         self.vocab = vocab\n",
    "#         self.max_seq_len = max_seq_len\n",
    "#         self.specials = specials\n",
    "#         self.CLS, self.PAD, self.MASK = specials['CLS'], specials['PAD'], specials['MASK']\n",
    "#         self.device = device\n",
    "#         self.ab = defined_antibiotics[selected_ab_idx]\n",
    "        \n",
    "#         self.phenotypes = self.ds['phenotypes'].tolist()\n",
    "#         self.year_col = self.ds['year'].astype(str).tolist()\n",
    "#         self.country_col = self.ds['country'].tolist()\n",
    "        \n",
    "#         self.columns = ['indices_masked', 'token_types', 'attn_mask', 'target_res', 'masked_sequences']\n",
    "        \n",
    "#     def prepare_dataset(self):\n",
    "#         masked_phenotypes = []\n",
    "#         target_caz_res = []\n",
    "#         for phen_list in self.phenotypes:\n",
    "#             masked_phen_list = []\n",
    "#             for p in phen_list:\n",
    "#                 if p.split('_')[0] != self.ab:\n",
    "#                     masked_phen_list.append(p)\n",
    "#                     # pass\n",
    "#                 else:\n",
    "#                     if p == self.ab+'_R':\n",
    "#                         target_caz_res.append(1)\n",
    "#                     else:\n",
    "#                         target_caz_res.append(0)\n",
    "#                     masked_phen_list.append(specials['MASK'])\n",
    "#             masked_phenotypes.append(masked_phen_list)\n",
    "\n",
    "#         masked_sequences = [[specials['CLS'], self.year_col[i], self.country_col[i]] + masked_phenotypes[i] for i in range(len(self.ds))]\n",
    "#         token_types = [[0]*5 + [2]*(len(masked_sequences[i])-5) for i in range(len(self.ds))]\n",
    "#         masked_sequences = [seq + [pad_token]*(max_seq_len-len(seq)) for seq in masked_sequences]\n",
    "#         indices_masked = [vocab.lookup_indices(masked_seq) for masked_seq in masked_sequences]\n",
    "#         token_types = [tt + [2]*(max_seq_len-len(tt)) for tt in token_types]\n",
    "#         attn_mask = [[False if token == pad_token else True for token in seq] for seq in masked_sequences]\n",
    "        \n",
    "#         rows = zip(indices_masked, token_types, attn_mask, target_caz_res, masked_sequences)\n",
    "#         self.df = pd.DataFrame(rows, columns=self.columns)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.ds)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = self.df.iloc[idx]\n",
    "        \n",
    "#         input = torch.tensor(item['indices_masked'], dtype=torch.long, device=self.device)\n",
    "#         token_types = torch.tensor(item['token_types'], dtype=torch.long, device=self.device)\n",
    "#         masked_sequences = item['masked_sequences']\n",
    "#         target_res = torch.tensor(item['target_res'], dtype=torch.float, device=self.device)\n",
    "#         attn_mask = (input != self.vocab[self.PAD]).unsqueeze(0).unsqueeze(1)\n",
    "        \n",
    "#         return input, token_types, attn_mask, target_res\n",
    "\n",
    "# CAZ_idx = ab_to_idx['CAZ']\n",
    "# CIP_idx = ab_to_idx['CIP']\n",
    "# AMP_idx = ab_to_idx['AMP']\n",
    "# GEN_idx = ab_to_idx['GEN']\n",
    "# CTX_idx = ab_to_idx['CTX']\n",
    "# ab_idx = CAZ_idx\n",
    "# selected_ab = defined_antibiotics[ab_idx]\n",
    "# print(\"ab idx (ab):\", ab_idx, selected_ab)\n",
    "\n",
    "# num_samples_NCBI = len(ds_NCBI_CAZ)\n",
    "# ds_inference_NCBI = MMInferenceDataset_NCBI(ds_NCBI_CAZ, vocab, defined_antibiotics, max_seq_len, specials, ab_idx)\n",
    "# inference_loader_NCBI = DataLoader(ds_inference_NCBI, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected ab: CIP\n",
      "Number of samples in inference dataset: 34404\n",
      "Number of batches in inference loader: 68\n",
      "==================================================\n",
      "Total CIP accuracy: 0.8478\n",
      "Data imbalance (R_share) of CIP: 0.2210\n",
      "Share of predictions that were CIP_R: 0.1091\n",
      "Share of predictions that were CIP_S: 0.8909\n",
      "Total CIP_R accuracy: 0.4025\n",
      "Precision: 0.8153\n",
      "Total CIP_S accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bert.eval_mode()\n",
    "# ds = ds_inference_NCBI\n",
    "# loader = inference_loader_NCBI  \n",
    "ds = ds_inference\n",
    "loader = inference_loader\n",
    "ds.prepare_dataset()\n",
    "print(\"selected ab:\", selected_ab)\n",
    "print(\"Number of samples in inference dataset:\", len(ds))\n",
    "print(\"Number of batches in inference loader:\", len(loader))\n",
    "print(\"=\"*50)\n",
    "tot_num_S, tot_num_R = 0, 0\n",
    "tot_correct, tot_num_correct_S, tot_num_correct_R = 0, 0, 0\n",
    "tot_num_pred_S, tot_num_pred_R = 0, 0\n",
    "for input, token_types, attn_mask, target_res in loader:\n",
    "    pred_logits = bert(input, token_types, attn_mask)\n",
    "    pred_res = torch.where(pred_logits > 0, torch.ones_like(pred_logits), torch.zeros_like(pred_logits))\n",
    "    ab_preds = pred_res[:, ab_idx]\n",
    "    num_R_pred = ab_preds.sum().item()\n",
    "    tot_num_pred_R += num_R_pred\n",
    "    num_S_pred = ab_preds.shape[0] - num_R_pred\n",
    "    tot_num_pred_S += num_S_pred \n",
    "        \n",
    "    num_S = target_res.eq(0).sum().item()\n",
    "    tot_num_S += num_S\n",
    "    num_R = target_res.eq(1).sum().item()\n",
    "    tot_num_R += num_R\n",
    "    \n",
    "    eq = torch.eq(pred_res[:, ab_idx], target_res)\n",
    "    num_correct = eq.sum().item()\n",
    "    tot_correct += num_correct\n",
    "    num_correct_R = eq[target_res == 1].sum().item()\n",
    "    tot_num_correct_R += num_correct_R\n",
    "    num_correct_S = eq[target_res == 0].sum().item()\n",
    "    tot_num_correct_S += num_correct_S\n",
    "    num_R_pred = pred_res[:, ab_idx].sum().item()\n",
    "print(f\"Total {selected_ab} accuracy: {tot_correct/(tot_num_S+tot_num_R):.4f}\")\n",
    "print(f\"Data imbalance (R_share) of {selected_ab}: {tot_num_R/(tot_num_S+tot_num_R):.4f}\")\n",
    "print(f\"Share of predictions that were {selected_ab}_R: {tot_num_pred_R/(tot_num_S+tot_num_R):.4f}\")\n",
    "print(f\"Share of predictions that were {selected_ab}_S: {tot_num_pred_S/(tot_num_S+tot_num_R):.4f}\")\n",
    "print(f\"Total {selected_ab}_R accuracy: {tot_num_correct_R/tot_num_R:.4f}\")\n",
    "if tot_num_pred_R > 0:\n",
    "    print(f\"Precision: {tot_num_correct_R/tot_num_pred_R:.4f}\")\n",
    "print(f\"Total {selected_ab}_S accuracy: {tot_num_correct_S/tot_num_S:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARFusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
