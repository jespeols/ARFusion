{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results request - CAZ_R performance on TESSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import wandb\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "BASE_DIR = Path(os.path.abspath(''))\n",
    "sys.path.append(str(BASE_DIR))\n",
    "os.chdir(BASE_DIR)\n",
    "\n",
    "# user-defined modules\n",
    "from pheno.models import BERT\n",
    "\n",
    "# user-defined functions\n",
    "from utils import get_split_indices, export_results, get_average_and_std_df\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(\"config_pheno.yaml\"))\n",
    "data_config = config['data']\n",
    "defined_antibiotics = sorted(list(set(data_config['antibiotics']['abbr_to_names'].keys()) - set(data_config['exclude_antibiotics'])))\n",
    "ab_to_idx = {ab: idx for idx, ab in enumerate(defined_antibiotics)}\n",
    "specials = config['specials']\n",
    "cls_token, pad_token, mask_token = specials['CLS'], specials['PAD'], specials['MASK']\n",
    "max_seq_len = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMK': 0,\n",
       " 'AMP': 1,\n",
       " 'CAZ': 2,\n",
       " 'CIP': 3,\n",
       " 'CRO': 4,\n",
       " 'CTX': 5,\n",
       " 'ETP': 6,\n",
       " 'FEP': 7,\n",
       " 'GEN': 8,\n",
       " 'IPM': 9,\n",
       " 'LVX': 10,\n",
       " 'MEM': 11,\n",
       " 'MFX': 12,\n",
       " 'NAL': 13,\n",
       " 'TOB': 14,\n",
       " 'TZP': 15}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare dataset for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in TESSy: 3,300,633\n"
     ]
    }
   ],
   "source": [
    "# ds_path = data_config['TESSy']['load_path']\n",
    "# ds_path = 'data/TESSy_15_all_pathogens.pkl'\n",
    "ds_path = 'data/TESSy_16_all_pathogens.pkl'\n",
    "ds_TESSy = pd.read_pickle(ds_path)\n",
    "print(f\"Total number of samples in TESSy: {len(ds_TESSy):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAZ_R experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected samples: 326,877\n"
     ]
    }
   ],
   "source": [
    "# antibiotics = ['CAZ', 'CIP', 'AMP', 'GEN']\n",
    "antibiotics = ['CAZ', 'CIP', 'AMP', 'GEN', 'TZP']\n",
    "ds_CAZ = ds_TESSy.copy()\n",
    "ds_CAZ['phenotypes'] = ds_CAZ['phenotypes'].apply(lambda x: [p for p in x if p.split('_')[0] in antibiotics])\n",
    "# ds_CAZ = ds_CAZ[ds_CAZ['phenotypes'].apply(lambda x: 'CAZ_R' in x)].reset_index(drop=True)\n",
    "ds_CAZ = ds_CAZ[ds_CAZ['phenotypes'].apply(lambda x: all([ab in [p.split('_')[0] for p in x] for ab in antibiotics]))].reset_index(drop=True)\n",
    "ds_CAZ.drop(columns=['num_R', 'num_S', 'num_ab'], inplace=True)\n",
    "ds_CAZ = ds_CAZ.sample(frac=1, random_state=config['random_state']).reset_index(drop=True)\n",
    "print(f\"Number of selected samples: {len(ds_CAZ):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIP_R experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected samples in ds_CIP: 34,404\n"
     ]
    }
   ],
   "source": [
    "antibiotics = ['CIP', 'AMP', 'CAZ', 'CTX', 'CRO', 'ETP', 'FEP']\n",
    "ds_CIP = ds_TESSy.copy()\n",
    "ds_CIP['phenotypes'] = ds_CIP['phenotypes'].apply(lambda x: [p for p in x if p.split('_')[0] in antibiotics])\n",
    "# ds_CIP = ds_CIP[ds_CIP['phenotypes'].apply(lambda x: 'CIP_R' in x)].reset_index(drop=True)\n",
    "ds_CIP = ds_CIP[ds_CIP['phenotypes'].apply(lambda x: all([ab in [p.split('_')[0] for p in x] for ab in antibiotics]))].reset_index(drop=True)\n",
    "ds_CIP.drop(columns=['num_R', 'num_S', 'num_ab'], inplace=True)\n",
    "ds_CIP = ds_CIP.sample(frac=1, random_state=config['random_state']).reset_index(drop=True)\n",
    "print(f\"Number of selected samples in ds_CIP: {len(ds_CIP):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected ab: CAZ\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# vocab_path = BASE_DIR / \"pheno_vocab_15_50p.pt\" # 50% of the data\n",
    "# vocab_path = BASE_DIR / \"pheno_vocab_15.pt\" \n",
    "vocab_path = BASE_DIR / \"pheno_vocab_16.pt\"\n",
    "vocab = torch.load(vocab_path)\n",
    "\n",
    "class MMInferenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds, vocab, defined_antibiotics, max_seq_len, specials, selected_ab_idx):\n",
    "        self.ds = ds\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.specials = specials\n",
    "        self.CLS, self.PAD, self.MASK = specials['CLS'], specials['PAD'], specials['MASK']\n",
    "        self.device = device\n",
    "        self.ab = defined_antibiotics[selected_ab_idx]\n",
    "        \n",
    "        self.phenotypes = self.ds['phenotypes'].tolist()\n",
    "        self.year_col = self.ds['year'].astype(str).tolist()\n",
    "        self.country_col = self.ds['country'].tolist()\n",
    "        self.gender_col = self.ds['gender'].tolist()\n",
    "        self.age_col = self.ds['age'].astype(int).astype(str).tolist()\n",
    "        \n",
    "        self.columns = ['indices_masked', 'attn_mask', 'target_res', 'masked_sequences']\n",
    "        \n",
    "    def prepare_dataset(self):\n",
    "        masked_phenotypes = []\n",
    "        target_res = []\n",
    "        for phen_list in self.phenotypes:\n",
    "            masked_phen_list = []\n",
    "            for p in phen_list:\n",
    "                if p.split('_')[0] != self.ab:\n",
    "                    masked_phen_list.append(p)\n",
    "                    pass    # only patient data\n",
    "                else:\n",
    "                    if p == self.ab+'_R':\n",
    "                        target_res.append(1)\n",
    "                    else:\n",
    "                        target_res.append(0)\n",
    "                    # masked_phen_list.append(p) ### TEMPORARY TEST - leaves what is to be predicted ####\n",
    "                    masked_phen_list.append(specials['MASK'])\n",
    "            masked_phenotypes.append(masked_phen_list)\n",
    "\n",
    "        masked_sequences = [[specials['CLS'], self.year_col[i], self.country_col[i], self.gender_col[i], self.age_col[i]] + masked_phenotypes[i] for i in range(len(self.ds))]\n",
    "        masked_sequences = [seq + [pad_token]*(max_seq_len-len(seq)) for seq in masked_sequences]\n",
    "        indices_masked = [vocab.lookup_indices(masked_seq) for masked_seq in masked_sequences]\n",
    "        attn_mask = [[False if token == pad_token else True for token in seq] for seq in masked_sequences]\n",
    "        \n",
    "        rows = zip(indices_masked, attn_mask, target_res, masked_sequences)\n",
    "        self.df = pd.DataFrame(rows, columns=self.columns)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "        \n",
    "        input = torch.tensor(item['indices_masked'], dtype=torch.long, device=self.device)\n",
    "        masked_sequences = item['masked_sequences']\n",
    "        target_res = torch.tensor(item['target_res'], dtype=torch.float, device=self.device)\n",
    "        attn_mask = (input != self.vocab[self.PAD]).unsqueeze(0).unsqueeze(1)\n",
    "        \n",
    "        return input, attn_mask, target_res\n",
    "\n",
    "CAZ_idx = ab_to_idx['CAZ']\n",
    "CIP_idx = ab_to_idx['CIP']\n",
    "AMP_idx = ab_to_idx['AMP']\n",
    "GEN_idx = ab_to_idx['GEN']\n",
    "CTX_idx = ab_to_idx['CTX']\n",
    "\n",
    "ds = ds_CAZ.copy()\n",
    "num_samples = 40000\n",
    "ab_idx = CAZ_idx\n",
    "\n",
    "# ds = ds_CIP.copy()\n",
    "# num_samples = len(ds_CIP)\n",
    "# ab_idx = CIP_idx\n",
    "\n",
    "selected_ab = defined_antibiotics[ab_idx]\n",
    "print(\"selected ab:\", selected_ab)\n",
    "\n",
    "ds_inference = MMInferenceDataset(ds.iloc[:num_samples], vocab, defined_antibiotics, max_seq_len, specials, ab_idx)\n",
    "inference_loader = DataLoader(ds_inference, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load vocab & fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected ab CAZ\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "## patient_data/patient_data+pheno\n",
    "# model_name = '0.2'                                # dumb/dumb for CAZ, 0./0 for CIP\n",
    "# model_name = '0.2_WL'                             # 0.30/0.53 for CAZ, 0.36/0.41 for CIP\n",
    "# model_name = '0.4'                                # dumb/0.22 for CAZ, 0./0. for CIP\n",
    "# model_name = '0.4_WL'                             # 0.01/0.48 for CAZ, 0./0. for CIP\n",
    "# model_name = '0.4_strong_WL'                      # dumb/0.49 for CAZ, 0./0. for CIP\n",
    "# model_name = '0.8'                                # dumb/dumb for CAZ, 0./0. for CIP\n",
    "# model_name = '0.8_WL'                             # dumb/0.05 for CAZ, 0./0. for CIP\n",
    "# model_name = '0.8_strong_WL'                      # 0.04/0.48 for CAZ, 0./0. for CIP\n",
    "# model_name = '1known'                             # 0.03/0.17 for CAZ, 0./0. for CIP\n",
    "# model_name = '1_known_WL'                         # dumb/0.18 for CAZ, 0./0. for CIP\n",
    "# model_name = '2_known'                            # dumb/0.27 for CAZ, 0./0. for CIP\n",
    "# model_name = '2known_WL'                          # dumb/0.33 for CAZ, 0./0. for CIP\n",
    "model_path = f'results/pheno/{model_name}/model_state.pt'\n",
    "num_ab = 15\n",
    "\n",
    "dim = 512\n",
    "config['emb_dim'] = dim\n",
    "config['ff_dim'] = dim\n",
    "config['hidden_dim'] = dim\n",
    "\n",
    "bert = BERT(\n",
    "    config,\n",
    "    vocab_size=vocab_size,\n",
    "    max_seq_len=max_seq_len,\n",
    "    num_ab=num_ab,\n",
    "    pad_idx=vocab[pad_token],\n",
    ").to(device)\n",
    "print(\"selected ab\", selected_ab)\n",
    "# print(\"Randomly initialized model:\")\n",
    "# print(bert.classification_layer[ab_idx].state_dict()['classifier.3.weight'])\n",
    "# print(bert.classification_layer[ab_idx].state_dict()['classifier.3.bias'])\n",
    "# print(\"Saved model:\")\n",
    "# print(torch.load(model_path)['ab_predictors'][ab_idx]['classifier.3.weight'])\n",
    "# print(torch.load(model_path)['ab_predictors'][ab_idx]['classifier.3.bias'])\n",
    "bert.set_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an inference *evaluator*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_ab: CAZ\n",
      "Number of samples in inference dataset: 40000\n",
      "Number of batches in inference loader: 79\n",
      "==================================================\n",
      "Total CAZ accuracy: 0.9996\n",
      "Data imbalance (R_share) of CAZ: 9.5%\n",
      "Share of predictions that were CAZ_R: 0.0945\n",
      "Share of predictions that were CAZ_S: 0.9055\n",
      "Total CAZ_R accuracy: 0.9960\n",
      "Precision: 1.0000\n",
      "Total CAZ_S accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "bert.eval_mode() \n",
    "ds = ds_inference\n",
    "loader = inference_loader\n",
    "ds.prepare_dataset()\n",
    "print(\"selected_ab:\", selected_ab)\n",
    "print(\"Number of samples in inference dataset:\", len(ds))\n",
    "print(\"Number of batches in inference loader:\", len(loader))\n",
    "print(\"=\"*50)\n",
    "tot_num_S, tot_num_R = 0, 0\n",
    "tot_correct, tot_num_correct_S, tot_num_correct_R = 0, 0, 0\n",
    "tot_num_pred_S, tot_num_pred_R = 0, 0\n",
    "for input, attn_mask, target_res in loader:\n",
    "    pred_logits = bert(input, attn_mask)\n",
    "    pred_res = torch.where(pred_logits > 0, torch.ones_like(pred_logits), torch.zeros_like(pred_logits))\n",
    "    ab_preds = pred_res[:, ab_idx]\n",
    "    num_R_pred = ab_preds.sum().item()\n",
    "    tot_num_pred_R += num_R_pred\n",
    "    num_S_pred = ab_preds.shape[0] - num_R_pred\n",
    "    tot_num_pred_S += num_S_pred \n",
    "        \n",
    "    num_S = target_res.eq(0).sum().item()\n",
    "    tot_num_S += num_S\n",
    "    num_R = target_res.eq(1).sum().item()\n",
    "    tot_num_R += num_R\n",
    "    \n",
    "    eq = torch.eq(pred_res[:, ab_idx], target_res)\n",
    "    num_correct = eq.sum().item()\n",
    "    tot_correct += num_correct\n",
    "    num_correct_R = eq[target_res == 1].sum().item()\n",
    "    tot_num_correct_R += num_correct_R\n",
    "    num_correct_S = eq[target_res == 0].sum().item()\n",
    "    tot_num_correct_S += num_correct_S\n",
    "    num_R_pred = pred_res[:, ab_idx].sum().item()\n",
    "num_samples = tot_num_S + tot_num_R\n",
    "print(f\"Total {selected_ab} accuracy: {tot_correct/num_samples:.4f}\")\n",
    "print(f\"Data imbalance (R_share) of {selected_ab}: {tot_num_R/(num_samples):.1%}\")\n",
    "print(f\"Share of predictions that were {selected_ab}_R: {tot_num_pred_R/(num_samples):.4f}\")\n",
    "print(f\"Share of predictions that were {selected_ab}_S: {tot_num_pred_S/(num_samples):.4f}\")\n",
    "print(f\"Total {selected_ab}_R accuracy: {tot_num_correct_R/tot_num_R:.4f}\")\n",
    "if tot_num_pred_R > 0:\n",
    "    print(f\"Precision: {tot_num_correct_R/tot_num_pred_R:.4f}\")\n",
    "print(f\"Total {selected_ab}_S accuracy: {tot_num_correct_S/tot_num_S:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARFusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
